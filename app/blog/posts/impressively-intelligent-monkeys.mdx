---
title: 'Impressively intelligent monkeys'
publishedAt: '2025-02-12'
summary: 'Humans and LLMs are equally likely to produce unoriginal data'
minuteRead: 6
image: '/assets/blog/impressively-intelligent-monkeys/cover.jpeg'
tags: ['philosophy', 'machine-learning']
---

<InfoBox message="TLDR: Humans and LLMs are equally likely to produce unoriginal data"/>

We humans live and must live in a particular form of social structure - a structure so ingrained it might as well be in our DNA. This isn't just a random accident of evolution.

Effective communication and collaboration - two important factors that have kept us alive and helped us build the world we would be comfortable to live in (*maybe not exactly comfortable yet*).

Letters, the printing press, books, and now the Internet. Each of these inventions significantly boosted our ability to share ideas and collaborate to materialize those ideas. It's almost as if every milestone in human history helped us getting better at talking to one another. 

At the same time, all these years of human evolution makes you think of the dynamics of human intelligence progress. Are we smarter on average than 50 years ago? Is the curve trending over time or only the knowledge we prioritize to keep for that time period is changing?



## Non-player behaviour

So far, it seems we are quite intelligent beings. Maybe that's why we've evolved more in the last 200 years than in the previous 2000+ years?!

Yet, we still are inclined to form our opinions based on others opinions. Now you may say, "Just because you're a pea-brained - it doesn't mean others are too" or "I'm mostly right and believe opinions are of my own".

But have you ever paused to wonder how exactly did you form "your" perspective? It doesn't necessarily have to be a blend of what you've picked up from your friends, colleagues surrounding you right now. Even the articles you read online are someone else's opinion. In fact, you might not have even reached this part of the article, and jumped into comments to see what others think. So, one shouldn't be offended when I say: in some ways, you're just another speaking monkey. Like with many things in animal behavior, monkeys likely do form their own opinions, but they are also heavily influenced by and rely on each other. Monkeys are brilliant in many ways, but when it comes to the art of communication and collaboration, we probably got lucky.

But that alone seems to be not enough, its most likely very easy for any influencer to steer a given group in a particular direction. Mass control is not a new science. It's all about the right words, the right tone, and the right timing. In one form or another, we all are victims - depending on what matches your values.


## Are we better than "Token predicting machine 2000"s?

Let's talk about Large Language Models (LLMs). A lot of people underestimate the importance of "predicting tokens". They say, it doesn't actually "think" and "understand" the way we do - it's just statistics - ultimate calculator of numbers to decide what word comes next. Funny enough to say, it's true in some sense. While others state "so is your brain...".

LLMs are evolving faster than you probably manage to get a raise these days (a quote worthy framing). And its much more complex than simple token prediction. It's usually a combination of many other clever technics, we clever monkeys been coming up with for the last few years. What a time to be alive!

You think you are somewhat smart and seem to have some reasoning skills too.
Think about your everyday conversations. When you greet a friend with "Hi", your brain doesn't generate words from scratch. It pulls up the "social greetings" section of your mental menu, where “how you doing?" sits near the top, pre-ranked by frequency, social norms, and past experience. This isn't robotic - it's efficient, like an LLM predicting the next token by selecting the most probable option from its “training data” (your lifetime of conversations). 

If you've ever learned a second language, you know that picking up common phrases is one of the quickest ways to get fluent. You collect these phrases *(may I have a bucket of chicken nuggets?)*, and over time, you build a mental map of how words and ideas connect - a grammar without actually learning the grammar - the way you would learn your native language!
In a way, you're creating your own little statistical model, not too different from how an LLM operates - bunch of points in your embedding space. We and neural networks rely on patterns and templates to make sense of language. With an exception that our model is a bit more dynamic on a time domain and, thankfully, less robotic. 

Think about it whenever you spit out a sentence.

**What is creativity?**

Some argue LLMs aren't capable of forming new ideas, the way they earlier claimed they aren't capable of being creative. We were mostly wrong about these predictions in our books and media. Yet, it's funny how our world likes irony - because some of the first areas where AI truly shined were in creative tasks. After all, what exactly is creativity? 

If you're inspired by nature or others, isn't creativity just a remix of what already exists or what you've particularly been exposed to? By that logic, if you can create something new by blending existing elements, then why shouldn't AI create a new [chimera](https://en.wikipedia.org/wiki/Chimera_(mythology)) and call it creative? It's like learning to draw by first copying the masters; sometimes, imitation is just the first step toward innovation.

Yes, they are fundamentally pattern-recognition and statistical prediction machines - but aren't we very close to that ourselves, especially when we're not under the influence (*joke*). 
This is a highly debatable topic that hinges on how you define "creativity" and whether you believe that genuine creativity requires consciousness, intentionality, subjective experience, or a deeper understanding of the world - qualities that today's LLMs maybe lack?! All those terms are complex on their own to define what is worthy to be of true "human nature". But its not far from the truth that they are getting there very soon - would you still call them "generative"?


**Dave Goggins type shi:**

We are not perfect and its not necessarily bad to get inspiration from others - as long as it sparks your own "creativity" and "innovation".  With all the progress in AI, for the last couple of years - the definition of artificial intelligence and intelligence itself is becoming more and more complicated and tricky. But maybe that's what makes us all delightfully, imperfectly human (or, in our case, impressively intelligent monkeys).